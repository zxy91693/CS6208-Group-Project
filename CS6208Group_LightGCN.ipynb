{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7804043-35a8-4471-9675-7cbd389ef014",
   "metadata": {},
   "source": [
    "# LightGCN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a49ebf-97a7-4e1a-b22a-5e11883c6374",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38a71e4b-2c22-46ed-91d9-269063c277b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import ipdb\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0718d71-30f6-4531-acf8-19e13e2e47fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, conf, ui_adj_graph):\n",
    "        super(LightGCN, self).__init__()\n",
    "        self.conf = conf\n",
    "        self.num_users = conf[\"n_users\"]\n",
    "        self.num_items = conf[\"n_items\"]\n",
    "        self.emb_size = self.conf['emb_size']\n",
    "        self.n_layer = self.conf['n_layer']\n",
    "        self.Graph = ui_adj_graph\n",
    "        self.__init_weight()\n",
    "\n",
    "\n",
    "    def __init_weight(self):\n",
    "        self.embedding_user = torch.nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.emb_size)\n",
    "        self.embedding_item = torch.nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=self.emb_size)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.embedding_user.weight, gain=1)\n",
    "        nn.init.xavier_uniform_(self.embedding_item.weight, gain=1)\n",
    "        self.f = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def propagate(self):\n",
    "        users_emb = self.embedding_user.weight\n",
    "        items_emb = self.embedding_item.weight\n",
    "        features = torch.cat([users_emb, items_emb])\n",
    "\n",
    "        embs = [features]\n",
    "\n",
    "        g_droped = self.Graph\n",
    "\n",
    "        for layer in range(self.n_layer):\n",
    "            features = torch.sparse.mm(g_droped, features)\n",
    "            features = F.normalize(features, p=2, dim=1)\n",
    "            embs.append(features)\n",
    "\n",
    "        light_out = torch.stack(embs, dim=1)\n",
    "        light_out = torch.sum(light_out, dim=1)\n",
    "\n",
    "        users, items = torch.split(light_out, [self.num_users, self.num_items])\n",
    "        return users, items\n",
    "\n",
    "\n",
    "    def getUsersRating(self, users):\n",
    "        all_users, all_items = self.propagate()\n",
    "        users_emb = all_users[users.long()]\n",
    "        items_emb = all_items\n",
    "        rating = self.f(torch.matmul(users_emb, items_emb.t()))\n",
    "\n",
    "        return rating\n",
    "\n",
    "\n",
    "    def getEmbedding(self, users, pos_items, neg_items):\n",
    "        all_users, all_items = self.propagate()\n",
    "        users_emb = all_users[users]\n",
    "        pos_emb = all_items[pos_items]\n",
    "        neg_emb = all_items[neg_items]\n",
    "        users_emb_ego = self.embedding_user(users)\n",
    "        pos_emb_ego = self.embedding_item(pos_items)\n",
    "        neg_emb_ego = self.embedding_item(neg_items)\n",
    "\n",
    "        return users_emb, pos_emb, neg_emb, users_emb_ego, pos_emb_ego, neg_emb_ego\n",
    "\n",
    "\n",
    "    def bpr_loss(self, users, pos, neg):\n",
    "        (users_emb, pos_emb, neg_emb,\n",
    "         userEmb0, posEmb0, negEmb0) = self.getEmbedding(users.long(), pos.long(), neg.long())\n",
    "        reg_loss = (1 / 2) * (userEmb0.norm(2).pow(2) +\n",
    "                              posEmb0.norm(2).pow(2) +\n",
    "                              negEmb0.norm(2).pow(2)) / float(len(users))\n",
    "        pos_scores = torch.mul(users_emb, pos_emb)\n",
    "        pos_scores = torch.sum(pos_scores, dim=1)\n",
    "        neg_scores = torch.mul(users_emb, neg_emb)\n",
    "        neg_scores = torch.sum(neg_scores, dim=1)\n",
    "\n",
    "        loss = torch.mean(torch.nn.functional.softplus(neg_scores - pos_scores))\n",
    "\n",
    "        return loss, reg_loss\n",
    "\n",
    "\n",
    "    def forward(self, batch):\n",
    "        user_ids, pos_ids, neg_ids = batch\n",
    "        bpr, L2_reg = self.bpr_loss(user_ids, pos_ids, neg_ids)\n",
    "        return bpr\n",
    "\n",
    "\n",
    "    def evaluate(self, propagate_result, users):\n",
    "        users_feature, item_feature = propagate_result\n",
    "        users_embedding = users_feature[users]\n",
    "        scores = torch.mm(users_embedding, item_feature.t())\n",
    "\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "661f4b5e-168e-4cc2-a8b7-c54b34c7c8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainData4UI(Dataset):\n",
    "    def __init__(self, conf, ui_pairs, ui_graph_train):\n",
    "        self.conf = conf\n",
    "        self.ui_pairs = ui_pairs\n",
    "        self.ui_graph = ui_graph_train\n",
    "        self.n_items = ui_graph_train.shape[1]\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ui_pairs)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return the train data\n",
    "        # Output: user, grd item, negative item\n",
    "        u, i = self.ui_pairs[idx]\n",
    "        j = random.randint(0, self.n_items-1)\n",
    "        while self.ui_graph[u, j] == 1:\n",
    "            j = random.randint(0, self.n_items-1)\n",
    "        return u, i, int(j)\n",
    "\n",
    "\n",
    "\n",
    "class TestData(Dataset):\n",
    "    def __init__(self, conf, ui_graph_test, ui_graph_train):\n",
    "        self.conf = conf\n",
    "        self.ui_graph_test = ui_graph_test\n",
    "        self.ui_graph_train = ui_graph_train\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ui_graph_test.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return the test data\n",
    "        # Output: index, grd test item sequence, train mask\n",
    "        grd = torch.from_numpy(self.ui_graph_test[idx].toarray()).squeeze()\n",
    "        train_mask = torch.from_numpy(self.ui_graph_train[idx].toarray()).squeeze()\n",
    "\n",
    "        return idx, grd, train_mask \n",
    "\n",
    "    \n",
    "class UI_Dataset():\n",
    "    def __init__(self, conf):\n",
    "        self.conf = conf\n",
    "        self.n_users, self.n_items = self.get_dataset_size()\n",
    "\n",
    "        self.ui_pairs_train, self.ui_graph_train = self.get_graph(\"train.txt\")\n",
    "        _, self.ui_graph_val = self.get_graph(\"valid.txt\")\n",
    "        _, self.ui_graph_test = self.get_graph(\"test.txt\")\n",
    "        \n",
    "\n",
    "        self.train_set = TrainData4UI(conf, self.ui_pairs_train, self.ui_graph_train)\n",
    "        self.train_loader = DataLoader(self.train_set, batch_size=conf[\"batch_size\"], shuffle=True, num_workers=conf[\"data_loader_num\"])\n",
    "        self.test_set = TestData(conf, self.ui_graph_test, self.ui_graph_train)\n",
    "        self.test_loader = DataLoader(self.test_set, batch_size=conf[\"test_batch_size\"], shuffle=False, num_workers=conf[\"data_loader_num\"])\n",
    "        self.val_set = TestData(conf, self.ui_graph_val, self.ui_graph_train)\n",
    "        self.val_loader = DataLoader(self.val_set, batch_size=conf[\"test_batch_size\"], shuffle=False, num_workers=conf[\"data_loader_num\"])\n",
    "\n",
    "        self.Graph = None\n",
    "    \n",
    "\n",
    "    def get_dataset_size(self):\n",
    "        target_path = self.conf[\"target_path\"]\n",
    "\n",
    "        n_users, n_items = 0, 0\n",
    "        for line in open(target_path + \"dataset_size.txt\"):\n",
    "            n_users, n_items = line.strip().split()\n",
    "            break\n",
    "\n",
    "        return int(n_users), int(n_items)\n",
    "\n",
    "\n",
    "    def get_graph(self, filename):\n",
    "        # Output: [user, item] pairs and the corresonding matrix\n",
    "        target_path = self.conf[\"target_path\"]\n",
    "\n",
    "        ui_pairs = []\n",
    "        for line in open(target_path + filename):\n",
    "            each = [int(x) for x in line.strip().split(\"\\t\")]\n",
    "            u = each[0]\n",
    "            for i in each[1:]:\n",
    "                ui_pairs.append([u, i])\n",
    "\n",
    "        indice = np.array(ui_pairs, dtype=np.int32)\n",
    "        values = np.ones(len(ui_pairs), dtype=np.float32)\n",
    "        ui_graph = sp.coo_matrix((values, (indice[:, 0], indice[:, 1])), shape=(self.n_users, self.n_items)).tocsr()\n",
    "\n",
    "        return ui_pairs, ui_graph\n",
    "\n",
    "    def getSparseGraph(self):\n",
    "        print(\"generating adjacency matrix\")\n",
    "        adj_mat = sp.dok_matrix((self.n_users + self.n_items, self.n_users + self.n_items), dtype=np.float32)\n",
    "        adj_mat = adj_mat.tolil()\n",
    "        R = self.ui_graph_train.tolil()\n",
    "        adj_mat[:self.n_users, self.n_users:] = R\n",
    "        adj_mat[self.n_users:, :self.n_users] = R.T\n",
    "        adj_mat = adj_mat.todok()\n",
    "\n",
    "        rowsum = np.array(adj_mat.sum(axis=1))\n",
    "        d_inv = np.power(rowsum, -0.5).flatten()\n",
    "        d_inv[np.isinf(d_inv)] = 0.\n",
    "        d_mat = sp.diags(d_inv)\n",
    "\n",
    "        norm_adj = d_mat.dot(adj_mat)\n",
    "        norm_adj = norm_adj.dot(d_mat)\n",
    "        norm_adj = norm_adj.tocsr()\n",
    "        sp.save_npz(self.conf['target_path'] + 's_pre_adj_mat.npz', norm_adj)\n",
    "\n",
    "        self.Graph = self._convert_sp_mat_to_sp_tensor(norm_adj)\n",
    "        self.Graph = self.Graph.coalesce().to(self.conf['device'])\n",
    "        return self.Graph\n",
    "\n",
    "    def _convert_sp_mat_to_sp_tensor(self, X):\n",
    "        coo = X.tocoo().astype(np.float32)\n",
    "        row = torch.Tensor(coo.row).long()\n",
    "        col = torch.Tensor(coo.col).long()\n",
    "        index = torch.stack([row, col])\n",
    "        data = torch.FloatTensor(coo.data)\n",
    "        return torch.sparse.FloatTensor(index, data, torch.Size(coo.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a03909cc-1870-4780-bc5f-d4133287f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_best_metrics(conf):\n",
    "    best_metrics = {}\n",
    "    best_metrics[\"val\"] = {}\n",
    "    best_metrics[\"test\"] = {}\n",
    "    for key in best_metrics:\n",
    "        best_metrics[key][\"recall\"] = {}\n",
    "        best_metrics[key][\"ndcg\"] = {}\n",
    "    for topk in conf['topk']:\n",
    "        for key in best_metrics:\n",
    "            for metric in best_metrics[key]:\n",
    "                best_metrics[key][metric][topk] = 0\n",
    "    best_perform = {}\n",
    "    best_perform[\"val\"] = {}\n",
    "    best_perform[\"test\"] = {}\n",
    "    return best_metrics, best_perform\n",
    "\n",
    "\n",
    "def write_log(log_path, topk, step, metrics):\n",
    "    curr_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    val_scores = metrics[\"val\"]\n",
    "    test_scores = metrics[\"test\"]\n",
    "\n",
    "    for m, val_score in val_scores.items():\n",
    "        test_score = test_scores[m]\n",
    "        \n",
    "    val_str = \"%s, Top_%d, Val:  recall: %f, ndcg: %f\" %(curr_time, topk, val_scores[\"recall\"][topk], val_scores[\"ndcg\"][topk])\n",
    "    test_str = \"%s, Top_%d, Test: recall: %f, ndcg: %f\" %(curr_time, topk, test_scores[\"recall\"][topk], test_scores[\"ndcg\"][topk])\n",
    "\n",
    "    log = open(log_path, \"a\")\n",
    "    log.write(\"%s\\n\" %(val_str))\n",
    "    log.write(\"%s\\n\" %(test_str))\n",
    "    log.close()\n",
    "    \n",
    "    print(val_str)\n",
    "    print(test_str)\n",
    "     \n",
    "\n",
    "def train(conf):\n",
    "    conf[\"device\"] = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "    for k, v in conf.items():\n",
    "        print(k, v)\n",
    "\n",
    "    dataset = UI_Dataset(conf)\n",
    "    conf['n_users'] = dataset.n_users\n",
    "    conf['n_items'] = dataset.n_items\n",
    "    \n",
    "    log_path = \"./log/\"\n",
    "    checkpoint_path = \"./checkpoints/\"\n",
    "    if not os.path.isdir(log_path):\n",
    "        os.makedirs(log_path)\n",
    "    if not os.path.isdir(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "\n",
    "    settings = []\n",
    "\n",
    "    settings += [ \"LR\"+str(conf['lr']),\"emb\"+str(conf['emb_size']), \"bs\"+str(conf['batch_size']), \"WD\"+str(conf['weight_decay']), 'epoch'+str(conf['num_epoches']), 'pop'+str(conf['pop']), time.strftime(\"%m_%d\", time.localtime())] \n",
    "\n",
    "    setting = \"_\".join(settings)\n",
    "    log_path = log_path + \"/\" + setting\n",
    "    checkpoint_path = checkpoint_path + \"/\" + setting\n",
    "\n",
    "    model = LightGCN(conf, dataset.getSparseGraph())\n",
    "\n",
    "    model.to(device=conf[\"device\"])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=conf[\"lr\"], weight_decay=conf['weight_decay'])\n",
    "    print(\"%s start training ... \"%datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    batch_cnt = len(dataset.train_loader)\n",
    "    test_interval_bs = int(batch_cnt * conf[\"test_interval\"])\n",
    "    best_metrics, best_perform = init_best_metrics(conf)\n",
    "    best_epoch = 0\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(conf[\"num_epoches\"]):\n",
    "        epoch_anchor = epoch * batch_cnt\n",
    "        model.train(True)\n",
    "        pbar = tqdm(enumerate(dataset.train_loader), total=len(dataset.train_loader))\n",
    "\n",
    "        for batch_i, batch in pbar:\n",
    "            model.train(True)\n",
    "            optimizer.zero_grad()\n",
    "            batch = [x.to(conf[\"device\"]) for x in batch]\n",
    "            batch_anchor = epoch_anchor + batch_i\n",
    "\n",
    "            loss = model(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_scalar = loss.detach()\n",
    "            pbar.set_description(\"epoch: %d, loss: %.4f\" %(epoch, loss_scalar))\n",
    "\n",
    "            # Test\n",
    "            if (batch_anchor + 1) % test_interval_bs == 0:\n",
    "                metrics = {}\n",
    "\n",
    "                metrics[\"val\"] = test(model, dataset.val_loader, conf)\n",
    "                metrics[\"test\"] = test(model, dataset.test_loader, conf)\n",
    "\n",
    "                best_metrics, best_perform, best_epoch = log_metrics(conf, model, metrics, log_path, checkpoint_path, epoch, batch_anchor, best_metrics, best_perform, best_epoch)\n",
    "\n",
    "        # early stopping\n",
    "        if epoch >= 10 and epoch-best_epoch>=20:\n",
    "            break\n",
    "\n",
    "\n",
    "def log_metrics(conf, model, metrics, log_path, checkpoint_path, epoch, batch_anchor, best_metrics, best_perform, best_epoch):\n",
    "    for topk in conf[\"topk\"]:\n",
    "        write_log(log_path, topk, batch_anchor, metrics)\n",
    "\n",
    "    log = open(log_path, \"a\")\n",
    "\n",
    "    topk_ = 20\n",
    "    print(\"top%d as the final evaluation standard\" %(topk_))\n",
    "    if metrics[\"val\"][\"recall\"][topk_] > best_metrics[\"val\"][\"recall\"][topk_] and metrics[\"val\"][\"ndcg\"][topk_] > best_metrics[\"val\"][\"ndcg\"][topk_]:\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        best_epoch = epoch\n",
    "        curr_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        for topk in conf['topk']:\n",
    "            for key, res in best_metrics.items():\n",
    "                for metric in res:\n",
    "                    best_metrics[key][metric][topk] = metrics[key][metric][topk]\n",
    "\n",
    "            best_perform[\"test\"][topk] = \"%s, Best in epoch %d, TOP %d: REC_T=%.5f, NDCG_T=%.5f\" %(curr_time, best_epoch, topk, best_metrics[\"test\"][\"recall\"][topk], best_metrics[\"test\"][\"ndcg\"][topk])\n",
    "            best_perform[\"val\"][topk] = \"%s, Best in epoch %d, TOP %d: REC_V=%.5f, NDCG_V=%.5f\" %(curr_time, best_epoch, topk, best_metrics[\"val\"][\"recall\"][topk], best_metrics[\"val\"][\"ndcg\"][topk])\n",
    "            print(best_perform[\"val\"][topk])\n",
    "            print(best_perform[\"test\"][topk])\n",
    "            log.write(best_perform[\"val\"][topk] + \"\\n\")\n",
    "            log.write(best_perform[\"test\"][topk] + \"\\n\")\n",
    "\n",
    "    log.close()\n",
    "\n",
    "    return best_metrics, best_perform, best_epoch\n",
    "\n",
    "\n",
    "def test(model, dataloader, conf):\n",
    "    '''\n",
    "\n",
    "    Run model on the validation or test data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: the trained model\n",
    "    dataloader: validation or test data loader\n",
    "    conf: model configuration\n",
    "    cold_mask: the mask of the cold items\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    metrics: recall and ndcg for topk\n",
    "    '''\n",
    "    tmp_metrics = {}\n",
    "    for m in [\"recall\", \"ndcg\"]:\n",
    "        tmp_metrics[m] = {}\n",
    "        for topk in conf[\"topk\"]:\n",
    "            tmp_metrics[m][topk] = [0, 0]\n",
    "\n",
    "    device = conf[\"device\"]\n",
    "    model.eval()\n",
    "    \n",
    "    rs = model.propagate()\n",
    "    m = 0\n",
    "    for batch_cnt, batch in enumerate(dataloader):\n",
    "\n",
    "        users, ground_truth, train_mask = batch\n",
    "        users = users.to(conf['device'])\n",
    "        ground_truth = ground_truth.to(conf['device'])\n",
    "        \n",
    "        if train_mask.shape[0] != m:\n",
    "            m = train_mask.shape[0]\n",
    "\n",
    "\n",
    "        pred = model.evaluate(rs, users.to(device))\n",
    "        torch.cuda.empty_cache()\n",
    "        pred -= 1e8 * train_mask.to(conf[\"device\"])\n",
    "        pred = pred.to(conf['device'])\n",
    "        tmp_metrics = get_metrics(tmp_metrics, ground_truth, pred, conf[\"topk\"])\n",
    "\n",
    "    metrics = {}\n",
    "    for m, topk_res in tmp_metrics.items():\n",
    "        metrics[m] = {}\n",
    "        for topk, res in topk_res.items():\n",
    "            metrics[m][topk] = res[0] / res[1]\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_metrics(metrics, grd, pred, topks):\n",
    "    tmp = {\"recall\": {}, \"ndcg\": {}}\n",
    "\n",
    "    for topk in topks:\n",
    "        _, col_indice = torch.topk(pred, topk)\n",
    "        row_indice = torch.zeros_like(col_indice) + torch.arange(pred.shape[0], device=pred.device, dtype=torch.long).view(-1, 1)\n",
    "        is_hit = grd[row_indice.view(-1), col_indice.view(-1)].view(-1, topk)\n",
    "\n",
    "        tmp[\"recall\"][topk] = get_recall(pred, grd, is_hit, topk)\n",
    "        tmp[\"ndcg\"][topk] = get_ndcg(pred, grd, is_hit, topk)\n",
    "\n",
    "    for m, topk_res in tmp.items():\n",
    "        for topk, res in topk_res.items():\n",
    "            for i, x in enumerate(res):\n",
    "                metrics[m][topk][i] += x\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def get_recall(pred, grd, is_hit, topk):\n",
    "    \n",
    "    epsilon = 1e-8\n",
    "    hit_cnt = is_hit.sum(dim=1)\n",
    "    num_pos = grd.sum(dim=1)\n",
    "    \n",
    "    # Remove those test cases who don't have any positive items\n",
    "    denorm = pred.shape[0] - (num_pos == 0).sum().item()\n",
    "    nomina = (hit_cnt/(num_pos+epsilon)).sum().item()\n",
    "    \n",
    "    return [nomina, denorm]\n",
    "\n",
    "\n",
    "def get_ndcg(pred, grd, is_hit, topk):\n",
    "\n",
    "    def DCG(hit, topk, device):\n",
    "        hit = hit.to(device)\n",
    "        hit = hit/torch.log2(torch.arange(2, topk+2, device=device, dtype=torch.float))\n",
    "        return hit.sum(-1)\n",
    "\n",
    "    def IDCG(num_pos, topk, device):\n",
    "        hit = torch.zeros(topk, dtype=torch.float)\n",
    "        hit[:num_pos] = 1\n",
    "        return DCG(hit, topk, device)\n",
    "\n",
    "    device = grd.device\n",
    "    IDCGs = torch.empty(1+topk, dtype=torch.float)\n",
    "    # Avoid 0/0\n",
    "    IDCGs[0] = 1  \n",
    "    for i in range(1, topk+1):\n",
    "        IDCGs[i] = IDCG(i, topk, device)\n",
    "\n",
    "    num_pos = grd.sum(dim=1).clamp(0, topk).to(torch.long)\n",
    "    dcg = DCG(is_hit, topk, device)\n",
    "    idcg = IDCGs[num_pos]\n",
    "    ndcg = dcg/idcg.to(device)\n",
    "\n",
    "    # Remove those test cases who don't have any positive items\n",
    "    denorm = pred.shape[0] - (num_pos == 0).sum().item()\n",
    "    nomina = ndcg.sum().item()\n",
    "\n",
    "    return [nomina, denorm]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4220f19-c327-4ff7-af14-2bdbe06fc01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {}\n",
    "\n",
    "conf['target_path'] = './data/' \n",
    "conf['emb_size'] = 64\n",
    "conf['n_layer'] = 2\n",
    "conf['lr'] = 0.001\n",
    "conf['weight_decay'] = 1.0e-7\n",
    "conf['num_epoches'] = 100\n",
    "conf['batch_size'] = 2048\n",
    "conf['test_batch_size'] = 2048\n",
    "conf['test_interval'] = 5\n",
    "conf['data_loader_num'] = 10\n",
    "\n",
    "conf['topk'] = [20,50,100]\n",
    "\n",
    "conf['pop'] = 0\n",
    "\n",
    "train(conf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
